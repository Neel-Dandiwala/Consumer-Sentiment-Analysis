{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3a094c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/u189511/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77637614",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('train_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3d9669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDLink</th>\n",
       "      <th>Title</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Topic</th>\n",
       "      <th>PublishDate</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>GooglePlus</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>SentimentTitle</th>\n",
       "      <th>SentimentHeadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tr3CMgRv1N</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemetery</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
       "      <td>USA TODAY</td>\n",
       "      <td>obama</td>\n",
       "      <td>2002-04-02 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wc81vGp8qZ</td>\n",
       "      <td>A Look at the Health of the Chinese Economy</td>\n",
       "      <td>Tim Haywood, investment director business-unit...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>economy</td>\n",
       "      <td>2008-09-20 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>-0.156386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zNGH03CrZH</td>\n",
       "      <td>Nouriel Roubini: Global Economy Not Back to 2008</td>\n",
       "      <td>Nouriel Roubini, NYU professor and chairman at...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>economy</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.425210</td>\n",
       "      <td>0.139754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3sM1H0W8ts</td>\n",
       "      <td>Finland GDP Expands In Q4</td>\n",
       "      <td>Finland's economy expanded marginally in the t...</td>\n",
       "      <td>RTT News</td>\n",
       "      <td>economy</td>\n",
       "      <td>2015-03-01 00:06:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wUbnxgvqaZ</td>\n",
       "      <td>Tourism, govt spending buoys Thai economy in J...</td>\n",
       "      <td>Tourism and public spending continued to boost...</td>\n",
       "      <td>The Nation - Thailand&amp;#39;s English news</td>\n",
       "      <td>economy</td>\n",
       "      <td>2015-03-01 00:11:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55927</th>\n",
       "      <td>jQ3CeLRCb9</td>\n",
       "      <td>Fidel Castro Lashes Out at Obama After Cuba Visit</td>\n",
       "      <td>Retired Cuban leader Fidel Castro slammed Pres...</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "      <td>obama</td>\n",
       "      <td>2016-03-29 01:35:06</td>\n",
       "      <td>794</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.135417</td>\n",
       "      <td>-0.055902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55928</th>\n",
       "      <td>akNYeJ8opY</td>\n",
       "      <td>JOHN CRISP | Obama's strategic reaction to Bru...</td>\n",
       "      <td>President Obama caught some predictable flak f...</td>\n",
       "      <td>Kitsap Sun</td>\n",
       "      <td>obama</td>\n",
       "      <td>2016-03-29 01:35:08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236228</td>\n",
       "      <td>0.056110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55929</th>\n",
       "      <td>n2DGs0c8IG</td>\n",
       "      <td>Think Trump's 45 Percent Tariffs Are Bad? Try ...</td>\n",
       "      <td>While Trump wants to put large tariffs on impo...</td>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>obama</td>\n",
       "      <td>2016-03-29 01:35:09</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025747</td>\n",
       "      <td>0.114820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55930</th>\n",
       "      <td>P0EBiaSEjq</td>\n",
       "      <td>Microsoft finally releases giant Surface</td>\n",
       "      <td>Microsoft’s business customers are finally beg...</td>\n",
       "      <td>TechEye</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>2016-03-29 01:38:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.028296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55931</th>\n",
       "      <td>99MLvyAQTJ</td>\n",
       "      <td>Rays of sunshine in the US economy</td>\n",
       "      <td>AS WE all know from listening to the campaign ...</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>economy</td>\n",
       "      <td>2016-03-29 01:41:08</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55932 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           IDLink                                              Title  \\\n",
       "0      Tr3CMgRv1N   Obama Lays Wreath at Arlington National Cemetery   \n",
       "1      Wc81vGp8qZ        A Look at the Health of the Chinese Economy   \n",
       "2      zNGH03CrZH   Nouriel Roubini: Global Economy Not Back to 2008   \n",
       "3      3sM1H0W8ts                          Finland GDP Expands In Q4   \n",
       "4      wUbnxgvqaZ  Tourism, govt spending buoys Thai economy in J...   \n",
       "...           ...                                                ...   \n",
       "55927  jQ3CeLRCb9  Fidel Castro Lashes Out at Obama After Cuba Visit   \n",
       "55928  akNYeJ8opY  JOHN CRISP | Obama's strategic reaction to Bru...   \n",
       "55929  n2DGs0c8IG  Think Trump's 45 Percent Tariffs Are Bad? Try ...   \n",
       "55930  P0EBiaSEjq           Microsoft finally releases giant Surface   \n",
       "55931  99MLvyAQTJ                 Rays of sunshine in the US economy   \n",
       "\n",
       "                                                Headline  \\\n",
       "0      Obama Lays Wreath at Arlington National Cemete...   \n",
       "1      Tim Haywood, investment director business-unit...   \n",
       "2      Nouriel Roubini, NYU professor and chairman at...   \n",
       "3      Finland's economy expanded marginally in the t...   \n",
       "4      Tourism and public spending continued to boost...   \n",
       "...                                                  ...   \n",
       "55927  Retired Cuban leader Fidel Castro slammed Pres...   \n",
       "55928  President Obama caught some predictable flak f...   \n",
       "55929  While Trump wants to put large tariffs on impo...   \n",
       "55930  Microsoft’s business customers are finally beg...   \n",
       "55931  AS WE all know from listening to the campaign ...   \n",
       "\n",
       "                                         Source      Topic  \\\n",
       "0                                     USA TODAY      obama   \n",
       "1                                     Bloomberg    economy   \n",
       "2                                     Bloomberg    economy   \n",
       "3                                      RTT News    economy   \n",
       "4      The Nation - Thailand&#39;s English news    economy   \n",
       "...                                         ...        ...   \n",
       "55927                       Wall Street Journal      obama   \n",
       "55928                                Kitsap Sun      obama   \n",
       "55929                           Huffington Post      obama   \n",
       "55930                                   TechEye  microsoft   \n",
       "55931                           Washington Post    economy   \n",
       "\n",
       "               PublishDate  Facebook  GooglePlus  LinkedIn  SentimentTitle  \\\n",
       "0      2002-04-02 00:00:00        -1          -1        -1        0.000000   \n",
       "1      2008-09-20 00:00:00        -1          -1        -1        0.208333   \n",
       "2      2012-01-28 00:00:00        -1          -1        -1       -0.425210   \n",
       "3      2015-03-01 00:06:00        -1          -1        -1        0.000000   \n",
       "4      2015-03-01 00:11:00        -1          -1        -1        0.000000   \n",
       "...                    ...       ...         ...       ...             ...   \n",
       "55927  2016-03-29 01:35:06       794          10         5       -0.135417   \n",
       "55928  2016-03-29 01:35:08         0           0         0        0.236228   \n",
       "55929  2016-03-29 01:35:09       102           4         0        0.025747   \n",
       "55930  2016-03-29 01:38:00         0           0         0        0.000000   \n",
       "55931  2016-03-29 01:41:08        75           7        19        0.000000   \n",
       "\n",
       "       SentimentHeadline  \n",
       "0              -0.053300  \n",
       "1              -0.156386  \n",
       "2               0.139754  \n",
       "3               0.026064  \n",
       "4               0.141084  \n",
       "...                  ...  \n",
       "55927          -0.055902  \n",
       "55928           0.056110  \n",
       "55929           0.114820  \n",
       "55930          -0.028296  \n",
       "55931           0.184444  \n",
       "\n",
       "[55932 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "723e96dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55932 entries, 0 to 55931\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   IDLink             55932 non-null  object \n",
      " 1   Title              55932 non-null  object \n",
      " 2   Headline           55932 non-null  object \n",
      " 3   Source             55757 non-null  object \n",
      " 4   Topic              55932 non-null  object \n",
      " 5   PublishDate        55932 non-null  object \n",
      " 6   Facebook           55932 non-null  int64  \n",
      " 7   GooglePlus         55932 non-null  int64  \n",
      " 8   LinkedIn           55932 non-null  int64  \n",
      " 9   SentimentTitle     55932 non-null  float64\n",
      " 10  SentimentHeadline  55932 non-null  float64\n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7581d844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDLink                 0\n",
       "Title                  0\n",
       "Headline               0\n",
       "Source               175\n",
       "Topic                  0\n",
       "PublishDate            0\n",
       "Facebook               0\n",
       "GooglePlus             0\n",
       "LinkedIn               0\n",
       "SentimentTitle         0\n",
       "SentimentHeadline      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65568109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b240058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55932 entries, 0 to 55931\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   IDLink             55932 non-null  object \n",
      " 1   Title              55932 non-null  object \n",
      " 2   Headline           55932 non-null  object \n",
      " 3   Source             55757 non-null  object \n",
      " 4   Topic              55932 non-null  object \n",
      " 5   PublishDate        55932 non-null  object \n",
      " 6   Facebook           55932 non-null  int64  \n",
      " 7   GooglePlus         55932 non-null  int64  \n",
      " 8   LinkedIn           55932 non-null  int64  \n",
      " 9   SentimentTitle     55932 non-null  float64\n",
      " 10  SentimentHeadline  55932 non-null  float64\n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13212777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "606e24a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDLink</th>\n",
       "      <th>SentimentTitle</th>\n",
       "      <th>SentimentHeadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CZLVHanbC2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.014113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VFkR6aHMVJ</td>\n",
       "      <td>0.080799</td>\n",
       "      <td>-0.038613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P7iEhVkGlM</td>\n",
       "      <td>-0.045645</td>\n",
       "      <td>-0.120476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ij5NwOmhCO</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.094653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AZhpvyzDfC</td>\n",
       "      <td>0.291663</td>\n",
       "      <td>0.094658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K68BWTk8nY</td>\n",
       "      <td>0.044194</td>\n",
       "      <td>0.058465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>m95WZhuovK</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.326718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4qwM4lsvYm</td>\n",
       "      <td>0.043212</td>\n",
       "      <td>-0.088388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u8iGT7DY2a</td>\n",
       "      <td>-0.079057</td>\n",
       "      <td>0.083853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3clx8GUpzY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IDLink  SentimentTitle  SentimentHeadline\n",
       "0  CZLVHanbC2        0.000000          -0.014113\n",
       "1  VFkR6aHMVJ        0.080799          -0.038613\n",
       "2  P7iEhVkGlM       -0.045645          -0.120476\n",
       "3  ij5NwOmhCO        0.291667           0.094653\n",
       "4  AZhpvyzDfC        0.291663           0.094658\n",
       "5  K68BWTk8nY        0.044194           0.058465\n",
       "6  m95WZhuovK        0.000000           0.326718\n",
       "7  4qwM4lsvYm        0.043212          -0.088388\n",
       "8  u8iGT7DY2a       -0.079057           0.083853\n",
       "9  3clx8GUpzY        0.000000           0.063732"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('sample.csv')\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb55a228-6c50-4975-94f3-9c71e6d48b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data[training_data['Facebook'].notna()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "703d65e2-a42c-459a-b082-fd10513029b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDLink                 0\n",
       "Title                  0\n",
       "Headline               0\n",
       "Source               175\n",
       "Topic                  0\n",
       "PublishDate            0\n",
       "Facebook               0\n",
       "GooglePlus             0\n",
       "LinkedIn               0\n",
       "SentimentTitle         0\n",
       "SentimentHeadline      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93f28db1-d8b0-4532-a190-61e664662916",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8aecb3-6918-4a4c-8e5c-95cd7a3580f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDLink               0\n",
       "Title                0\n",
       "Headline             0\n",
       "Source               0\n",
       "Topic                0\n",
       "PublishDate          0\n",
       "Facebook             0\n",
       "GooglePlus           0\n",
       "LinkedIn             0\n",
       "SentimentTitle       0\n",
       "SentimentHeadline    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df0b3dc3-6afd-4790-8fbb-89c14bf2eab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_file.csv')\n",
    "test_data\n",
    "source = list(training_data['Source'])\n",
    "topic = list(training_data['Topic'])\n",
    "publishDate = list(training_data['PublishDate'])\n",
    "facebook = list(training_data['Facebook'])\n",
    "googlePlus = list(training_data['GooglePlus'])\n",
    "linkedIn = list(training_data['LinkedIn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01996781-f6cd-43e5-a8e8-bc4c138f1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentTitle = list(training_data['SentimentTitle'])\n",
    "sentimentHeadline = list(training_data['SentimentHeadline'])\n",
    "\n",
    "training_sentimentTitle = sentimentTitle[0:40575]\n",
    "testing_sentimentTitle = sentimentTitle[40575:]\n",
    "\n",
    "training_sentimentHeadline = sentimentHeadline[0:40575]\n",
    "testing_sentimentHeadline = sentimentHeadline[40575:]\n",
    "\n",
    "title = list(training_data['Title'])\n",
    "headline = list(training_data['Headline'])\n",
    "\n",
    "len(max(headline, key=len))\n",
    "\n",
    "training_title = title[0:40575]\n",
    "testing_title = title[40575:]\n",
    "\n",
    "training_headline = headline[0:40575]\n",
    "testing_headline = headline[40575:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9127929c-c3da-4986-9c0a-312b222b5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=100000, oov_token=\"<OOV>\")\n",
    "# tokenizer.fit_on_texts(training_title)\n",
    "# tokenizer.fit_on_texts(training_headline)\n",
    "\n",
    "# word_index = tokenizer.word_index\n",
    "\n",
    "# training_titleSequences = tokenizer.texts_to_sequences(training_title)\n",
    "# training_paddedTitle = pad_sequences(training_titleSequences, maxlen=170, padding='post', truncating='post')\n",
    "\n",
    "# testing_titleSequences = tokenizer.texts_to_sequences(testing_title)\n",
    "# testing_paddedTitle = pad_sequences(testing_titleSequences, maxlen=170, padding='post', truncating='post')\n",
    "\n",
    "# training_headlineSequences = tokenizer.texts_to_sequences(training_headline)\n",
    "# training_paddedHeadline = pad_sequences(training_headlineSequences, maxlen=446, padding='post', truncating='post')\n",
    "\n",
    "# testing_headlineSequences = tokenizer.texts_to_sequences(testing_headline)\n",
    "# testing_paddedHeadline = pad_sequences(testing_headlineSequences, maxlen=446, padding='post', truncating='post')\n",
    "\n",
    "# training_paddedTitle = np.array(training_paddedTitle)\n",
    "# testing_paddedTitle = np.array(testing_paddedTitle)\n",
    "# training_paddedHeadline = np.array(training_paddedHeadline)\n",
    "# testing_paddedHeadline = np.array(testing_paddedHeadline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33cb411c-9fda-4f71-814e-2b0df51401aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(title)\n",
    "tokenizer.fit_on_texts(headline)\n",
    "tokenizer.fit_on_texts(topic)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "    \n",
    "titleSequences = tokenizer.texts_to_sequences(title)\n",
    "#170\n",
    "paddedTitle = pad_sequences(titleSequences, maxlen=None, padding='post', truncating='post')\n",
    "\n",
    "headlineSequences = tokenizer.texts_to_sequences(headline)\n",
    "# paddedHeadline = pad_sequences(headlineSequences, maxlen=446, padding='post', truncating='post')\n",
    "paddedHeadline = pad_sequences(headlineSequences, maxlen=None, padding='post', truncating='post')\n",
    "\n",
    "sourceSequences = tokenizer.texts_to_sequences(source)\n",
    "paddedSource = pad_sequences(sourceSequences, maxlen=None, padding='post', truncating='post')\n",
    "\n",
    "topicSequences = tokenizer.texts_to_sequences(topic)\n",
    "paddedTopic = pad_sequences(topicSequences, maxlen=None, padding='post', truncating='post')\n",
    "\n",
    "paddedTitle = np.array(paddedTitle)\n",
    "paddedHeadline = np.array(paddedHeadline)\n",
    "paddedTopic = np.array(paddedTopic)\n",
    "paddedSource = np.array(paddedSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bfef9f6-6a96-46b6-bf27-75380a2100a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int32'>\n",
      "[4193  119    0    0    0    0    0    0    0    0    0]\n",
      "[9]\n"
     ]
    }
   ],
   "source": [
    "print(type(paddedHeadline[0][0]))\n",
    "print(paddedSource[0])\n",
    "print(paddedTopic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473bbcb-4682-41a1-9d88-61e9c358a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [paddedTitle, paddedHeadline, source, topic, publishDate, facebook, googlePlus, linkedIn, sentimentTitle, sentimentHeadline]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20167dae-61ed-4fe3-a77f-3389aa79580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_attribute_data = [np.array(x) for x in zip(paddedTitle, paddedHeadline, paddedSource, paddedTopic, facebook, googlePlus, linkedIn)]\n",
    "print(len(unified_attribute_data))\n",
    "unified_target_data = [np.array(x) for x in zip(sentimentTitle, sentimentHeadline)]\n",
    "print(len(unified_target_data))\n",
    "unified_attribute_data = np.array(unified_attribute_data)\n",
    "unified_target_data = np.array(unified_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a01f1709-3ce9-4456-a28a-671cc34e6790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obama\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2990], [1944], [6], [963], [6]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_words = [x.split() for x in title]\n",
    "title_words\n",
    "headline_words = [x.split() for x in headline]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "num_value = tokenizer.texts_to_sequences(headline_words[0][0])\n",
    "print(headline_words[0][0])\n",
    "print(tokenizer.word_index[(headline_words[0][0]).lower()])\n",
    "# print(tokenizer.word_index)\n",
    "num_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72fa89dc-086d-4cc3-8ac4-a72fdf3f0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_words = [x.split() for x in title]\n",
    "# title_words\n",
    "# headline_words = [x.split() for x in headline]\n",
    "# headline_words[0][0]\n",
    "\n",
    "import re\n",
    "title_words = [re.findall(r\"[\\w']+\", x) for x in title]\n",
    "headline_words = [re.findall(r\"[\\w']+\", x) for x in headline]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83c33213-0ea4-4b2f-bacc-113b69f59d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# modified_data = list()\n",
    "# attribute_data = list()\n",
    "# target_data = list()\n",
    "# for a in range(0, 55757):\n",
    "#     for b in range(0, len(headline_words[a])):\n",
    "#         if (headline_words[a][b]).lower() not in stop_words:\n",
    "#             # modified_data.append([headline_words[a][b], source[a], topic[a], publishDate[a], facebook[a], googlePlus[a], linkedIn[a]])\n",
    "#             for c in range(0, len(title_words[a])):\n",
    "#                 if (title_words[a][c]).lower() not in stop_words:\n",
    "#                     num_headline = tokenizer.word_index[(headline_words[a][b]).lower()]\n",
    "#                     num_title = tokenizer.word_index[(title_words[a][c]).lower()]\n",
    "#                     num_topic = tokenizer.word_index[(topic[a]).lower()]\n",
    "#                     modified_data.append([num_title, num_headline, num_topic, facebook[a], googlePlus[a], linkedIn[a], sentimentTitle[a], sentimentHeadline[a]])\n",
    "#                     attribute_data.append([num_title, num_headline, num_topic, facebook[a], googlePlus[a], linkedIn[a]])\n",
    "#                     target_data.append([sentimentTitle[a], sentimentHeadline[a]])\n",
    "                           \n",
    "# # SOURCE IS DELETED\n",
    "# print(attribute_data[0])\n",
    "# print(target_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7fbcb44-5558-40c3-98b2-fee751cd4fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, -1, -1, -1]\n",
      "[0.0, -0.0533001790889026]\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "num_modified_data = list()\n",
    "num_attribute_data = list()\n",
    "num_target_data = list()\n",
    "for a in range(0, 55757):\n",
    "    for b in range(0, len(headlineSequences[a])):\n",
    "        for c in range(0, len(titleSequences[a])):\n",
    "            num_topic = tokenizer.word_index[(topic[a]).lower()]\n",
    "            num_modified_data.append([titleSequences[a][c], headlineSequences[a][b], num_topic, facebook[a], googlePlus[a], linkedIn[a], sentimentTitle[a], sentimentHeadline[a]])\n",
    "            num_attribute_data.append([titleSequences[a][c], headlineSequences[a][b], num_topic, facebook[a], googlePlus[a], linkedIn[a]])\n",
    "            num_target_data.append([sentimentTitle[a], sentimentHeadline[a]])\n",
    "                           \n",
    "# SOURCE IS DELETED\n",
    "print(num_attribute_data[0])\n",
    "print(num_target_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e7f29c0-719a-4f87-9bd3-366798f32228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(np.array(num_attribute_data[:40000]), np.array(num_target_data[:40000]), random_state=42, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8bc35bd-7a09-4db9-a795-d9cb3171a3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000\n",
      "(28000, 6)\n",
      "(28000, 2)\n",
      "(12000, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(x_train))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e86ad93b-d0af-48bc-96d1-04f20104df5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 24)                168       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 26        \n",
      "=================================================================\n",
      "Total params: 494\n",
      "Trainable params: 494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.add(Dense(10, input_dim=5, kernel_initializer='uniform', activation='tanh'))\n",
    "#     model.add(Dropout(0.15))\n",
    "#     model.add(Dense(7, kernel_initializer='uniform', activation='relu'))\n",
    "#     model.add(Dropout(0.15))\n",
    "#     model.add(Dense(3,kernel_initializer='uniform', activation='sigmoid'))\n",
    "    \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(24,input_dim=6, activation='tanh'),\n",
    "    tf.keras.layers.Dense(12, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e46fc3b2-20a9-4f74-8c14-51a36fa743ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "28000/28000 - 2s - loss: -2.3154e-01 - acc: 0.1320 - val_loss: -9.1066e-01 - val_acc: 0.1346\n",
      "Epoch 2/10\n",
      "28000/28000 - 2s - loss: -3.6112e+00 - acc: 0.1352 - val_loss: -7.9851e+00 - val_acc: 0.1346\n",
      "Epoch 3/10\n",
      "28000/28000 - 2s - loss: -1.5477e+01 - acc: 0.1352 - val_loss: -2.4519e+01 - val_acc: 0.1346\n",
      "Epoch 4/10\n",
      "28000/28000 - 2s - loss: -3.5869e+01 - acc: 0.1352 - val_loss: -4.9680e+01 - val_acc: 0.1346\n",
      "Epoch 5/10\n",
      "28000/28000 - 2s - loss: -6.4195e+01 - acc: 0.1352 - val_loss: -8.1089e+01 - val_acc: 0.1346\n",
      "Epoch 6/10\n",
      "28000/28000 - 2s - loss: -9.8756e+01 - acc: 0.1352 - val_loss: -1.1878e+02 - val_acc: 0.1346\n",
      "Epoch 7/10\n",
      "28000/28000 - 2s - loss: -1.3628e+02 - acc: 0.1352 - val_loss: -1.6016e+02 - val_acc: 0.1346\n",
      "Epoch 8/10\n",
      "28000/28000 - 2s - loss: -1.8201e+02 - acc: 0.1351 - val_loss: -2.0711e+02 - val_acc: 0.1345\n",
      "Epoch 9/10\n",
      "28000/28000 - 2s - loss: -2.3028e+02 - acc: 0.1351 - val_loss: -2.5864e+02 - val_acc: 0.1344\n",
      "Epoch 10/10\n",
      "28000/28000 - 2s - loss: -2.8312e+02 - acc: 0.1349 - val_loss: -3.1564e+02 - val_acc: 0.1337\n"
     ]
    }
   ],
   "source": [
    "# training_attribute_data =  np.array(attribute_data[:5362151])\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1449aea-63ac-45d2-a109-16c3d062858a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be061f-4db8-4a4f-86bb-624fc54b71b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (OpenVINO 2020.3.2 LTS)",
   "language": "python",
   "name": "c003-python_3_lts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
