{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nO5TZ5o-SXYw",
    "outputId": "fefd053c-e90c-45db-a0b9-2f3ac0bd771f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: snorkel in /home/u189553/.local/lib/python3.6/site-packages (0.9.9)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages/tqdm-4.62.3-py3.6.egg (from snorkel) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.6/dist-packages (from snorkel) (1.18.5)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.6/dist-packages (from snorkel) (2.5.1)\n",
      "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from snorkel) (1.4.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.6/dist-packages/pandas-1.1.5-py3.6-linux-x86_64.egg (from snorkel) (1.1.5)\n",
      "Requirement already satisfied: munkres>=1.0.6 in /home/u189553/.local/lib/python3.6/site-packages (from snorkel) (1.1.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.6/dist-packages (from snorkel) (0.24.2)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /home/u189553/.local/lib/python3.6/site-packages (from snorkel) (2.10.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.6/dist-packages/scipy-1.5.4-py3.6-linux-x86_64.egg (from snorkel) (1.5.4)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.2->snorkel) (4.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.0->snorkel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages/pytz-2021.3-py3.6.egg (from pandas>=1.0.0->snorkel) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.2->snorkel) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.2->snorkel) (3.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (1.8.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (2.3.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (3.19.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (0.37.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (0.15.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (59.1.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (1.32.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.4->tensorboard>=2.9.1->snorkel) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->snorkel) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->snorkel) (4.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (2018.1.18)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (2.0.7)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->snorkel) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->snorkel) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->snorkel) (3.7.4.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->snorkel) (3.1.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in /home/u189553/.local/lib/python3.6/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages/nltk-3.6.5-py3.6.egg (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages/click-8.0.3-py3.6.egg (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.6/dist-packages/regex-2021.11.10-py3.6-linux-x86_64.egg (from nltk>=3.1->textblob) (2021.11.10)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages/tqdm-4.62.3-py3.6.egg (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from click->nltk>=3.1->textblob) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->click->nltk>=3.1->textblob) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->click->nltk>=3.1->textblob) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "#install needed packages\n",
    "!pip install snorkel\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "id": "SCyWn0UGSmMP"
   },
   "outputs": [],
   "source": [
    "#import libraries and modules\n",
    "import io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: snorkel in /home/u189553/.local/lib/python3.6/site-packages (0.9.9)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.6/dist-packages (from snorkel) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.6/dist-packages (from snorkel) (0.24.2)\n",
      "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from snorkel) (1.4.0)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /home/u189553/.local/lib/python3.6/site-packages (from snorkel) (2.10.1)\n",
      "Requirement already satisfied: munkres>=1.0.6 in /home/u189553/.local/lib/python3.6/site-packages (from snorkel) (1.1.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.6/dist-packages/scipy-1.5.4-py3.6-linux-x86_64.egg (from snorkel) (1.5.4)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.6/dist-packages/pandas-1.1.5-py3.6-linux-x86_64.egg (from snorkel) (1.1.5)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages/tqdm-4.62.3-py3.6.egg (from snorkel) (4.62.3)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.6/dist-packages (from snorkel) (2.5.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.2->snorkel) (4.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.0->snorkel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages/pytz-2021.3-py3.6.egg (from pandas>=1.0.0->snorkel) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.2->snorkel) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.2->snorkel) (3.0.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (0.37.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (3.19.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (0.15.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (2.3.3)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (1.32.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (59.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.9.1->snorkel) (0.4.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.4->tensorboard>=2.9.1->snorkel) (1.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->snorkel) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->snorkel) (4.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (2018.1.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->snorkel) (2.6)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->snorkel) (0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->snorkel) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->snorkel) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->snorkel) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->snorkel) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "id": "FiE5svlHTAR3"
   },
   "outputs": [],
   "source": [
    "#Snorkel\n",
    "from snorkel.labeling import LabelingFunction\n",
    "import re\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "from snorkel.labeling import labeling_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /home/u189553/.local/lib/python3.6/site-packages (3.5.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages/tqdm-4.62.3-py3.6.egg (from spacy) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (1.9.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (59.1.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.7.4.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/u189553/.local/lib/python3.6/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
      "Requirement already satisfied: dataclasses<1.0,>=0.6 in /usr/local/lib/python3.6/dist-packages (from pathy>=0.10.0->spacy) (0.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.1.18)\n",
      "Requirement already satisfied: contextvars<3,>=2.4 in /home/u189553/.local/lib/python3.6/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (2.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/u189553/.local/lib/python3.6/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/u189553/.local/lib/python3.6/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.6/dist-packages/click-8.0.3-py3.6.egg (from typer<0.8.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.6/dist-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy) (4.8.2)\n",
      "Requirement already satisfied: immutables>=0.9 in /home/u189553/.local/lib/python3.6/site-packages (from contextvars<3,>=2.4->thinc<8.2.0,>=8.1.8->spacy) (0.19)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaQ7LYgVTDkO",
    "outputId": "d9b57dac-64ba-46c2-89ec-f9546e500649"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/u189553/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#NLP packages\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import nltk.tokenize\n",
    "punc = string.punctuation\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "id": "J7rKAWVoTLmp"
   },
   "outputs": [],
   "source": [
    "#Supervised learning\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "##Deep learning libraries and APIs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6o9IRoZTXbm",
    "outputId": "12f9a391-be63-4c5b-d6b7-2de8af9d3706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55932 entries, 0 to 55931\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   IDLink             55932 non-null  object \n",
      " 1   Title              55932 non-null  object \n",
      " 2   Headline           55932 non-null  object \n",
      " 3   Source             55757 non-null  object \n",
      " 4   Topic              55932 non-null  object \n",
      " 5   PublishDate        55932 non-null  object \n",
      " 6   Facebook           55932 non-null  int64  \n",
      " 7   GooglePlus         55932 non-null  int64  \n",
      " 8   LinkedIn           55932 non-null  int64  \n",
      " 9   SentimentTitle     55932 non-null  float64\n",
      " 10  SentimentHeadline  55932 non-null  float64\n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# store the dataset as a Pandas Dataframe\n",
    "df = pd.read_csv('train_file.csv')\n",
    "df = pd.DataFrame()\n",
    "training_data = pd.read_csv('train_file.csv')\n",
    "#conduct some data cleaning\n",
    "# df = df.drop(['publish_date', 'Unnamme 'pd' is not defineded: 2'], axis=1)\n",
    "# df = df.rename(columns = {'headline_text': 'text'})\n",
    "# df['Title'] = df['Title'].astype(str)\n",
    "#check the data info\n",
    "training_data.head()\n",
    "training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5NkOqe7VA9t",
    "outputId": "12435605-9db1-4954-a108-4ae2a41db5f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/u189553/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "id": "y0cWkFXwVaSd"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "id": "rTGBSNYgV64v"
   },
   "outputs": [],
   "source": [
    "title = list(training_data['Title'])\n",
    "headline = list(training_data['Headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "id": "h3LPYmkiVyGv"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "title_words = [re.findall(r\"[\\w']+\", x) for x in title]\n",
    "training_data['Title'] = [re.findall(r\"[\\w']+\", x) for x in title]\n",
    "headline_words = [re.findall(r\"[\\w']+\", x) for x in headline]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJ1CQBaSWaiY",
    "outputId": "fd3fb35a-4fdb-4a8a-ed40-88effe118da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Obama', 'Lays', 'Wreath', 'at', 'Arlington', 'National', 'Cemetery']\n",
      "['Obama', 'Lays', 'Wreath', 'at', 'Arlington', 'National', 'Cemetery', 'President', 'Barack', 'Obama', 'has', 'laid', 'a', 'wreath', 'at', 'the', 'Tomb', 'of', 'the', 'Unknowns', 'to', 'honor']\n"
     ]
    }
   ],
   "source": [
    "print(title_words[0])\n",
    "print(headline_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "id": "jvmkRDMtZCmY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "id": "kIcRslA0W8L5",
    "outputId": "48c5dc07-2616-47ce-bed4-c3518a76dfd4"
   },
   "outputs": [],
   "source": [
    "# for wordList in list(title_words):  # iterating on a copy since removing will mess things up\n",
    "#   for word in wordList:\n",
    "#     if word in list(stop_words):\n",
    "#         wordList.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "id": "F4H21pczZdtC"
   },
   "outputs": [],
   "source": [
    "new_title_words = [];\n",
    "for wordList in title_words:\n",
    "    new_words = list(filter(lambda w: w not in stop_words,wordList))\n",
    "    new_title_words.append(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55932"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_title_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_titles = list(training_data['SentimentTitle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft', 'finally', 'releases', 'giant', 'Surface']"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Title'][55930]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "id": "kiVxUQvVUgX-"
   },
   "outputs": [],
   "source": [
    "#define constants to represent the class labels :positive, negative, and abstain\n",
    "POSITIVES = list()\n",
    "NEGATIVES = list()\n",
    "NEUTRALS =  list()\n",
    "#define function which looks into the input words to represent a proper label\n",
    "# def keyword_lookup(x, keywords, label):  \n",
    "#     if any(word in x.text.lower() for word in keywords):\n",
    "#         return label\n",
    "#     return ABSTAIN\n",
    "# #define function which assigns a correct label\n",
    "# def make_keyword_lf(keywords, label=POSITIVE):\n",
    "#     return LabelingFunction(\n",
    "#         name=f\"keyword_{keywords[0]}\",\n",
    "#         f=keyword_lookup,\n",
    "#         resources=dict(keywords=keywords, label=label))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for x in range(len(sentiment_titles)):\n",
    "    for i in new_title_words[x]:\n",
    "        if(sentiment_titles[x] < 0 ):\n",
    "            NEGATIVES.append(i)\n",
    "        elif(sentiment_titles[x] > 0 ):\n",
    "            POSITIVES.append(i)\n",
    "        elif(sentiment_titles[x] == 0 ):\n",
    "            NEUTRALS.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up a preprocessor function to determine polarity & subjectivity using textlob pretrained classifier \n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find polarity\n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return POSITIVES if x.polarity > 0.6 else NEUTRALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find subjectivity \n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_subjectivity(x):\n",
    "    return POSITIVES if x.subjectivity >= 0.5 else NEUTRALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_lookup(x, keywords, label):  \n",
    "    if any(word in x.text.lower() for word in keywords):\n",
    "        return label\n",
    "    return \"NEUTRAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_keyword_lf(keywords, label=\"POSITIVE\"):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all the labeling functions \n",
    "lfs = [make_keyword_lf(POSITIVES), make_keyword_lf(NEGATIVES), textblob_polarity, textblob_subjectivity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the lfs on the dataframe\n",
    "applier = PandasLFApplier(lfs=lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tqdm-4.62.3-py3.6.egg/tqdm/std.py:775: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  total = df.size // df.shape[axis]\n",
      "1it [00:00, 618.45it/s]\n"
     ]
    }
   ],
   "source": [
    "L_snorkel = applier.apply(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_title_words_df = pd.DataFrame(new_title_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obama</td>\n",
       "      <td>Lays</td>\n",
       "      <td>Wreath</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>National</td>\n",
       "      <td>Cemetery</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Look</td>\n",
       "      <td>Health</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Economy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nouriel</td>\n",
       "      <td>Roubini</td>\n",
       "      <td>Global</td>\n",
       "      <td>Economy</td>\n",
       "      <td>Not</td>\n",
       "      <td>Back</td>\n",
       "      <td>2008</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finland</td>\n",
       "      <td>GDP</td>\n",
       "      <td>Expands</td>\n",
       "      <td>In</td>\n",
       "      <td>Q4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tourism</td>\n",
       "      <td>govt</td>\n",
       "      <td>spending</td>\n",
       "      <td>buoys</td>\n",
       "      <td>Thai</td>\n",
       "      <td>economy</td>\n",
       "      <td>January</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55927</th>\n",
       "      <td>Fidel</td>\n",
       "      <td>Castro</td>\n",
       "      <td>Lashes</td>\n",
       "      <td>Out</td>\n",
       "      <td>Obama</td>\n",
       "      <td>After</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>Visit</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55928</th>\n",
       "      <td>JOHN</td>\n",
       "      <td>CRISP</td>\n",
       "      <td>Obama's</td>\n",
       "      <td>strategic</td>\n",
       "      <td>reaction</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55929</th>\n",
       "      <td>Think</td>\n",
       "      <td>Trump's</td>\n",
       "      <td>45</td>\n",
       "      <td>Percent</td>\n",
       "      <td>Tariffs</td>\n",
       "      <td>Are</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Try</td>\n",
       "      <td>Obama's</td>\n",
       "      <td>10000</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55930</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>finally</td>\n",
       "      <td>releases</td>\n",
       "      <td>giant</td>\n",
       "      <td>Surface</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55931</th>\n",
       "      <td>Rays</td>\n",
       "      <td>sunshine</td>\n",
       "      <td>US</td>\n",
       "      <td>economy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55932 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2          3         4         5        6   \\\n",
       "0          Obama      Lays    Wreath  Arlington  National  Cemetery     None   \n",
       "1              A      Look    Health    Chinese   Economy      None     None   \n",
       "2        Nouriel   Roubini    Global    Economy       Not      Back     2008   \n",
       "3        Finland       GDP   Expands         In        Q4      None     None   \n",
       "4        Tourism      govt  spending      buoys      Thai   economy  January   \n",
       "...          ...       ...       ...        ...       ...       ...      ...   \n",
       "55927      Fidel    Castro    Lashes        Out     Obama     After     Cuba   \n",
       "55928       JOHN     CRISP   Obama's  strategic  reaction  Brussels     None   \n",
       "55929      Think   Trump's        45    Percent   Tariffs       Are      Bad   \n",
       "55930  Microsoft   finally  releases      giant   Surface      None     None   \n",
       "55931       Rays  sunshine        US    economy      None      None     None   \n",
       "\n",
       "          7        8      9   ...    15    16    17    18    19    20    21  \\\n",
       "0       None     None   None  ...  None  None  None  None  None  None  None   \n",
       "1       None     None   None  ...  None  None  None  None  None  None  None   \n",
       "2       None     None   None  ...  None  None  None  None  None  None  None   \n",
       "3       None     None   None  ...  None  None  None  None  None  None  None   \n",
       "4       None     None   None  ...  None  None  None  None  None  None  None   \n",
       "...      ...      ...    ...  ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "55927  Visit     None   None  ...  None  None  None  None  None  None  None   \n",
       "55928   None     None   None  ...  None  None  None  None  None  None  None   \n",
       "55929    Try  Obama's  10000  ...  None  None  None  None  None  None  None   \n",
       "55930   None     None   None  ...  None  None  None  None  None  None  None   \n",
       "55931   None     None   None  ...  None  None  None  None  None  None  None   \n",
       "\n",
       "         22    23    24  \n",
       "0      None  None  None  \n",
       "1      None  None  None  \n",
       "2      None  None  None  \n",
       "3      None  None  None  \n",
       "4      None  None  None  \n",
       "...     ...   ...   ...  \n",
       "55927  None  None  None  \n",
       "55928  None  None  None  \n",
       "55929  None  None  None  \n",
       "55930  None  None  None  \n",
       "55931  None  None  None  \n",
       "\n",
       "[55932 rows x 25 columns]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_title_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_title_words_df = new_title_words_df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obama</td>\n",
       "      <td>Lays</td>\n",
       "      <td>Wreath</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>National</td>\n",
       "      <td>Cemetery</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Look</td>\n",
       "      <td>Health</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Economy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nouriel</td>\n",
       "      <td>Roubini</td>\n",
       "      <td>Global</td>\n",
       "      <td>Economy</td>\n",
       "      <td>Not</td>\n",
       "      <td>Back</td>\n",
       "      <td>2008</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finland</td>\n",
       "      <td>GDP</td>\n",
       "      <td>Expands</td>\n",
       "      <td>In</td>\n",
       "      <td>Q4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tourism</td>\n",
       "      <td>govt</td>\n",
       "      <td>spending</td>\n",
       "      <td>buoys</td>\n",
       "      <td>Thai</td>\n",
       "      <td>economy</td>\n",
       "      <td>January</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55927</th>\n",
       "      <td>Fidel</td>\n",
       "      <td>Castro</td>\n",
       "      <td>Lashes</td>\n",
       "      <td>Out</td>\n",
       "      <td>Obama</td>\n",
       "      <td>After</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>Visit</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55928</th>\n",
       "      <td>JOHN</td>\n",
       "      <td>CRISP</td>\n",
       "      <td>Obama's</td>\n",
       "      <td>strategic</td>\n",
       "      <td>reaction</td>\n",
       "      <td>Brussels</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55929</th>\n",
       "      <td>Think</td>\n",
       "      <td>Trump's</td>\n",
       "      <td>45</td>\n",
       "      <td>Percent</td>\n",
       "      <td>Tariffs</td>\n",
       "      <td>Are</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Try</td>\n",
       "      <td>Obama's</td>\n",
       "      <td>10000</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55930</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>finally</td>\n",
       "      <td>releases</td>\n",
       "      <td>giant</td>\n",
       "      <td>Surface</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55931</th>\n",
       "      <td>Rays</td>\n",
       "      <td>sunshine</td>\n",
       "      <td>US</td>\n",
       "      <td>economy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55932 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2          3         4         5        6   \\\n",
       "0          Obama      Lays    Wreath  Arlington  National  Cemetery            \n",
       "1              A      Look    Health    Chinese   Economy                      \n",
       "2        Nouriel   Roubini    Global    Economy       Not      Back     2008   \n",
       "3        Finland       GDP   Expands         In        Q4                      \n",
       "4        Tourism      govt  spending      buoys      Thai   economy  January   \n",
       "...          ...       ...       ...        ...       ...       ...      ...   \n",
       "55927      Fidel    Castro    Lashes        Out     Obama     After     Cuba   \n",
       "55928       JOHN     CRISP   Obama's  strategic  reaction  Brussels            \n",
       "55929      Think   Trump's        45    Percent   Tariffs       Are      Bad   \n",
       "55930  Microsoft   finally  releases      giant   Surface                      \n",
       "55931       Rays  sunshine        US    economy                                \n",
       "\n",
       "          7        8      9   ... 15 16 17 18 19 20 21 22 23 24  \n",
       "0                             ...                                \n",
       "1                             ...                                \n",
       "2                             ...                                \n",
       "3                             ...                                \n",
       "4                             ...                                \n",
       "...      ...      ...    ...  ... .. .. .. .. .. .. .. .. .. ..  \n",
       "55927  Visit                  ...                                \n",
       "55928                         ...                                \n",
       "55929    Try  Obama's  10000  ...                                \n",
       "55930                         ...                                \n",
       "55931                         ...                                \n",
       "\n",
       "[55932 rows x 25 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_title_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lays Wreath Arlington National Cemetery       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Look Health Chinese Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roubini Global Economy Not Back 2008          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GDP Expands In Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>govt spending buoys Thai economy January      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55927</th>\n",
       "      <td>Castro Lashes Out Obama After Cuba Visit      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55928</th>\n",
       "      <td>CRISP Obama's strategic reaction Brussels     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55929</th>\n",
       "      <td>Trump's 45 Percent Tariffs Are Bad Try Obama's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55930</th>\n",
       "      <td>finally releases giant Surface                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55931</th>\n",
       "      <td>sunshine US economy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55932 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title\n",
       "0      Lays Wreath Arlington National Cemetery       ...\n",
       "1        Look Health Chinese Economy                    \n",
       "2      Roubini Global Economy Not Back 2008          ...\n",
       "3                  GDP Expands In Q4                    \n",
       "4      govt spending buoys Thai economy January      ...\n",
       "...                                                  ...\n",
       "55927  Castro Lashes Out Obama After Cuba Visit      ...\n",
       "55928  CRISP Obama's strategic reaction Brussels     ...\n",
       "55929  Trump's 45 Percent Tariffs Are Bad Try Obama's...\n",
       "55930  finally releases giant Surface                ...\n",
       "55931           sunshine US economy                     \n",
       "\n",
       "[55932 rows x 1 columns]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "new_title_words_df\n",
    "# new_title_words_df = new_title_words_df.apply(lambda text: \" \".join(set(text)),axis=1)\n",
    "new_title_words_df['Title'] = new_title_words_df[new_title_words_df.columns[1:]].apply(\n",
    "    lambda x: ' '.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "new_title_words_df = new_title_words_df.iloc[:,25:]\n",
    "new_title_words_df\n",
    "# # new_title_words_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf_vect.fit_transform(new_title_words_df['Title'])\n",
    "print(X_tfidf.shape)\n",
    "print(tfidf_vect.get_feature_names())\n",
    "X_tfidf = pd.DataFrame(X_tfidf.toarray())\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_labels = list()\n",
    "for i in range(len(sentiment_titles)):\n",
    "    if(sentiment_titles[i] < 0):\n",
    "        title_labels.append(-1)\n",
    "    elif(sentiment_titles[i] > 0):\n",
    "        title_labels.append(1)\n",
    "    else:\n",
    "        title_labels.append(0)\n",
    "pd.DataFrame(title_labels)\n",
    "sentiment_titles_df = pd.DataFrame(title_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55932, 22014)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55932, 1)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_titles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.80      0.77      4593\n",
      "           0       0.67      0.48      0.56      2306\n",
      "           1       0.73      0.78      0.76      4288\n",
      "\n",
      "    accuracy                           0.73     11187\n",
      "   macro avg       0.71      0.69      0.70     11187\n",
      "weighted avg       0.72      0.73      0.72     11187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "X= X_tfidf\n",
    "y = sentiment_titles_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "#fit Log Regression Model\n",
    "clf= LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (OpenVINO 2020.3.2 LTS)",
   "language": "python",
   "name": "c003-python_3_lts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
